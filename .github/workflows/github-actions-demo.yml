name: Node.js AI Validation Pipeline (MCP Server)

# Triggers the pipeline on push to main or on any pull request
on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  build_and_validate:
    runs-on: ubuntu-latest
    
    # Define environment variables used by the AI Agents
    env:
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }} 

    steps:
      # 1. SETUP AND BASE CHECKS
      - name: Checkout Code
        uses: actions/checkout@v4
        
      - name: Setup Node.js Environment
        uses: actions/setup-node@v4
        with:
          node-version: 20.x
          cache: 'npm'

      - name: Install Dependencies and Agent Tools
        run: |
          npm ci
          # Install global tools needed for reporting and execution
          npm install -g snyk semgrep ts-node typescript artillery

      - name: Run Unit Tests (Base Gate)
        run: npm test

      # 2. DATA GATHERING FOR AI AGENTS
      - name: Gather All Reports and Context
        run: |
          echo "--- Starting Raw Data Collection for AI Agents ---"
          
          # Security Reports (Use '|| true' to ensure files are generated even if vulnerabilities are found)
          snyk test --json > snyk_report.json || true
          semgrep --config auto --json > semgrep_report.json || true
          
          # Performance Report (Requires app to be running, using || true to allow the pipeline to proceed)
          # NOTE: In a real environment, you would run a temporary deployment here.
          npx artillery quick --count 10 --num 5 --output performance_report.json 'http://localhost:3000/api/users' || true
          
          # Code Quality/Context (For all agents)
          git diff HEAD^ HEAD --no-color > code_changes.diff
          
          # Placeholder for ESLint report (required by the Quality Agent)
          # In a real pipeline, replace this with 'npx eslint --format json > eslint_report.json'
          echo '[]' > eslint_report.json 

      # 3. EXECUTE AI AGENTS
      - name: AI Security Agent üõ°Ô∏è
        run: ts-node llm-security-agent.ts > llm_security_report.json

      - name: AI Performance Agent ‚ö°
        run: ts-node llm-performance-agent.ts > llm_performance_report.json

      - name: AI Code Quality Agent ‚úîÔ∏è
        run: ts-node llm-quality-agent.ts > llm_quality_report.json

      # 4. ORCHESTRATION AND QUALITY GATE
      # This step FAILS the entire pipeline if the orchestrator determines the overall verdict is 'FAIL'
      - name: MCP Server Orchestration and Final Gate
        id: mcp_gate
        run: |
          # The orchestrator script exits with 1 on FAIL, enforcing the gate.
          ts-node mcp_orchestrator.ts
          
      # 5. POST FEEDBACK (PR Comment and Artifact Upload)
      
      # Always run this step, even if the MCP Gate failed, so feedback is provided.
      - name: Post AI Validation Summary to PR
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const core = require('@actions/core');

            if (!fs.existsSync('mcp_final_report.json')) {
                core.setFailed('FATAL: Orchestrator failed to produce mcp_final_report.json.');
                return;
            }

            const report = JSON.parse(fs.readFileSync('mcp_final_report.json', 'utf8'));

            // 1. Determine icon based on verdict
            let icon = '‚ö™'; // Default
            if (report.overall_verdict === 'FAIL') {
              icon = 'üî¥';
            } else if (report.overall_verdict === 'WARNING') {
              icon = '‚ö†Ô∏è';
            } else {
              icon = 'üü¢';
            }
            
            // 2. Build the detailed comment body
            let body = `# ${icon} Multi-Criteria Policy (MCP) Verdict: ${report.overall_verdict}\n\n`;
            body += `## üöÄ Summary: ${report.summary}\n\n`;
            
            body += '### Detailed Agent Reports\n';
            
            // Security Report
            let secIcon = report.results.security.verdict === 'PASS' ? '‚úÖ' : report.results.security.verdict === 'WARNING' ? '‚ö†Ô∏è' : '‚ùå';
            body += `* **Security Agent (${secIcon}):** ${report.results.security.summary}\n`;
            if (report.results.security.critical_issues && report.results.security.critical_issues.length > 0) {
              body += `  - Found **${report.results.security.critical_issues.length}** Critical/High issues.\n`;
            }
            
            // Performance Report
            let perfIcon = report.results.performance.verdict === 'PASS' ? '‚úÖ' : report.results.performance.verdict === 'WARNING' ? '‚ö†Ô∏è' : '‚ùå';
            body += `* **Performance Agent (${perfIcon}):** ${report.results.performance.summary}\n`;
            
            // Quality Report
            let qualIcon = report.results.quality.verdict === 'PASS' ? '‚úÖ' : report.results.quality.verdict === 'WARNING' ? '‚ö†Ô∏è' : '‚ùå';
            body += `* **Code Quality Agent (${qualIcon}):** ${report.results.quality.summary} (Score: ${report.results.quality.quality_score}/100)\n`;
            
            body += '\n---\n';
            body += `The full report JSON has been uploaded as a workflow artifact for debugging.`;

            // 3. Post the comment to the Pull Request
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            })
            
      - name: Upload Final Report Artifact
        uses: actions/upload-artifact@v4
        with:
          name: mcp-final-report-${{ github.sha }}
          path: mcp_final_report.json
          if-no-files-found: ignore
